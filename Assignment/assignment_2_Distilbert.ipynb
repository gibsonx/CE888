{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibsonx/CE888/blob/master/Assignment/assignment_2_Distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk0hIUcdXpi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6ea229-a861-47d5-ed26-9f88b086c35d"
      },
      "source": [
        "!pip install -U tensorflow tensorflow_datasets tensorflow_text zhon bert-for-tf2 sentencepiece focal-loss transformers tfa-nightly imbalanced-learn\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "!git clone https://github.com/cardiffnlp/tweeteval.git"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already up-to-date: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already up-to-date: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already up-to-date: zhon in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already up-to-date: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already up-to-date: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n",
            "Requirement already up-to-date: focal-loss in /usr/local/lib/python3.7/dist-packages (0.0.6)\n",
            "Requirement already up-to-date: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already up-to-date: tfa-nightly in /usr/local/lib/python3.7/dist-packages (0.13.0.dev20210409202352)\n",
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.1.2)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.29.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.11.0)\n",
            "Requirement already satisfied, skipping upgrade: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tfa-nightly) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "fatal: destination path 'tweeteval' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFgb6kZXX8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdd181e-17a0-42f9-9c07-b2bca103bcdb"
      },
      "source": [
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "import tensorflow_addons as tfa\n",
        "import os,pathlib,re,nltk,pickle,string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras import Input, layers, losses, preprocessing, utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.core import Dense,Dropout\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "# ML Libraries\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from zhon import hanzi \n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import csv\n",
        "import tokenization\n",
        "from focal_loss import BinaryFocalLoss\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from transformers import TFDistilBertModel,DistilBertTokenizer\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEXTeQYlY9Ss"
      },
      "source": [
        "# drive.mount('/content/drive/')\n",
        "base_dir = '/content/tweeteval/datasets/'\n",
        "hate_dir = base_dir + \"hate\"\n",
        "irony_dir = base_dir + \"irony\"\n",
        "offensive_dir = base_dir + \"offensive\""
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m98i1ZKv91Sh"
      },
      "source": [
        "def imbalance_under_sampling(dfname):\n",
        "  df_label_a = dfname[dfname['label'] == 1]\n",
        "  df_label_b = dfname[dfname['label'] == 0]\n",
        "  if df_label_a.shape[0] > df_label_b.shape[0]:\n",
        "  # count_class_0, count_class_1 = dfname.label.value_counts()\n",
        "    df_label_a = df_label_a.sample(df_label_b.shape[0],random_state=1)\n",
        "    df = pd.concat([df_label_b, df_label_a], axis=0)\n",
        "    print('label 0 is more',df.label.value_counts())  \n",
        "    return df\n",
        "  else: \n",
        "    df_label_b = df_label_b.sample(df_label_a.shape[0],random_state=1)\n",
        "    df = pd.concat([df_label_b, df_label_a], axis=0)\n",
        "    print('label 1 is more',df.label.value_counts())  \n",
        "    return df"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcveRCcrB1Kh"
      },
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    return emoji_pattern.sub(r'', string)\n",
        "\n",
        "def preprocess_tweet_text(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    # Remove urls\n",
        "    tweet = re.sub(r\"^#\\S+|\\s#\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "    # Remove user @ references and '#' from tweet\n",
        "    tweet = re.sub(r\"^@\\S+|\\s@\\S+\",'', tweet)\n",
        "    tweet = re.sub(r\"https?://\\S+\",'', tweet)\n",
        "    # Remove punctuations\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    tweet = tweet.translate(str.maketrans('', '', hanzi.punctuation))\n",
        "    tweet = remove_emoji(tweet)\n",
        "    # tweet_tokens = word_tokenize(tweet)\n",
        "    # # Remove stopwords\n",
        "    # filtered_words = [w for w in tweet_tokens]\n",
        "    # return \" \".join(filtered_words)\n",
        "    return tweet\n",
        "\n",
        "def readfile(text):\n",
        "  pd_list = []\n",
        "  with open(text,'r') as f:\n",
        "    for tweet in f.read().splitlines():\n",
        "      tweet = preprocess_tweet_text(tweet)\n",
        "      pd_list.append(tweet)   \n",
        "  return pd_list\n",
        " \n",
        "def readfile_label(text):\n",
        "  pd_list = []\n",
        "  with open(text,'r') as f:\n",
        "    for tweet in f.read().splitlines():\n",
        "      pd_list.append(int(tweet))  \n",
        "  return pd_list"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q0IWHEhEScP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "6d9c8986-abca-456e-bfe5-03abe8bdd0a3"
      },
      "source": [
        "#Pre-process csv and merge into a Dataframe\n",
        "#Hate DataFrame Data \n",
        "hate_dict_train = {'text': readfile(os.path.join(hate_dir,\"train_text.txt\")),'label': readfile_label(os.path.join(hate_dir,\"train_labels.txt\"))}\n",
        "hate_dict_val = {'text': readfile(os.path.join(hate_dir,\"val_text.txt\")),'label': readfile_label(os.path.join(hate_dir,\"val_labels.txt\"))}\n",
        "hate_dict_test = {'text': readfile(os.path.join(hate_dir,\"test_text.txt\")),'label': readfile_label(os.path.join(hate_dir,\"test_labels.txt\"))}\n",
        "hate_train_df = imbalance_under_sampling(pd.DataFrame(hate_dict_train))\n",
        "hate_val_df = pd.DataFrame(hate_dict_val)\n",
        "hate_test_df = pd.DataFrame(hate_dict_test)\n",
        "hate_frames = [hate_train_df, hate_val_df, hate_test_df]\n",
        "df_hate = pd.concat(hate_frames)\n",
        "not_hate = df_hate[df_hate['label'] == 0]\n",
        "hate = df_hate[df_hate['label'] == 1]\n",
        "\n",
        "#Irony DataFrame\n",
        "irony_dict_train = {'text': readfile(os.path.join(irony_dir,\"train_text.txt\")),'label': readfile_label(os.path.join(irony_dir,\"train_labels.txt\"))}\n",
        "irony_dict_val = {'text': readfile(os.path.join(irony_dir,\"val_text.txt\")),'label': readfile_label(os.path.join(irony_dir,\"val_labels.txt\"))}\n",
        "irony_dict_test = {'text': readfile(os.path.join(irony_dir,\"test_text.txt\")),'label': readfile_label(os.path.join(irony_dir,\"test_labels.txt\"))}\n",
        "irony_train_df = imbalance_under_sampling(pd.DataFrame(irony_dict_train))\n",
        "irony_val_df = pd.DataFrame(irony_dict_val)\n",
        "irony_test_df = pd.DataFrame(irony_dict_test)\n",
        "irony_frames = [irony_train_df,irony_val_df,irony_test_df]\n",
        "df_irony = pd.concat(irony_frames)\n",
        "not_irony  = df_irony[df_irony['label'] == 0]\n",
        "irony  = df_irony[df_irony['label'] == 1]\n",
        "\n",
        "#Offensive DataFrame\n",
        "offensive_dict_train = {'text': readfile(os.path.join(offensive_dir,\"train_text.txt\")),'label': readfile_label(os.path.join(offensive_dir,\"train_labels.txt\"))}\n",
        "offensive_dict_val = {'text': readfile(os.path.join(offensive_dir,\"val_text.txt\")),'label': readfile_label(os.path.join(offensive_dir,\"val_labels.txt\"))}\n",
        "offensive_dict_test = {'text': readfile(os.path.join(offensive_dir,\"test_text.txt\")),'label': readfile_label(os.path.join(offensive_dir,\"test_labels.txt\"))}\n",
        "offensive_train_df = imbalance_under_sampling(pd.DataFrame(offensive_dict_train))\n",
        "offensive_val_df = pd.DataFrame(offensive_dict_val)\n",
        "offensive_test_df = pd.DataFrame(offensive_dict_test)\n",
        "offensive_frames = [offensive_train_df,offensive_val_df,offensive_test_df]\n",
        "df_offensive = pd.concat(offensive_frames)\n",
        "not_offensive  = df_offensive[df_offensive['label'] == 0]\n",
        "offensive  = df_offensive[df_offensive['label'] == 1]\n",
        "\n",
        "offensive_test_df[offensive_test_df['label'] == 1]"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label 1 is more 1    3783\n",
            "0    3783\n",
            "Name: label, dtype: int64\n",
            "label 0 is more 1    1417\n",
            "0    1417\n",
            "Name: label, dtype: int64\n",
            "label 1 is more 1    3941\n",
            "0    3941\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is liar she is fat ugly libreal she sold her ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a grown ass woman probably 10 years older tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>is a disciple of anthony kennedy who ed liber...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>and apparently im committed to going to a new ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>50 cent calls out joe buddens bullshit on inst...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>do not represent all canadians   they are aut...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>s dt cycle track can easily open antifa tenni...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>and have a bitch thinking you niggas have mone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>852</th>\n",
              "      <td>and  least 16 other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>dont care what you postits propaganda</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>240 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  label\n",
              "0     is liar she is fat ugly libreal she sold her ...      1\n",
              "8     a grown ass woman probably 10 years older tha...      1\n",
              "10    is a disciple of anthony kennedy who ed liber...      1\n",
              "15   and apparently im committed to going to a new ...      1\n",
              "18   50 cent calls out joe buddens bullshit on inst...      1\n",
              "..                                                 ...    ...\n",
              "848   do not represent all canadians   they are aut...      1\n",
              "849   s dt cycle track can easily open antifa tenni...      1\n",
              "850  and have a bitch thinking you niggas have mone...      1\n",
              "852                               and  least 16 other       1\n",
              "857             dont care what you postits propaganda       1\n",
              "\n",
              "[240 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggIut-u18AmS"
      },
      "source": [
        "def bert_encode(tweets, tokenizer, max_len=512):\n",
        "    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n",
        "    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in tweets]\n",
        "    inp_tok = np.array([a['input_ids'] for a in inps])\n",
        "    ids = np.array([a['attention_mask'] for a in inps])\n",
        "    # segments = np.array([a['token_type_ids'] for a in inps])\n",
        "    return inp_tok, ids"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkaKgVCt-Ac6"
      },
      "source": [
        "#Create Bert Model\n",
        "def build_model(bert_layer, max_len=512):\n",
        "    ids = Input(shape=(max_len,), dtype=tf.int32, name=\"ids\")\n",
        "    mask = Input(shape=(max_len,), dtype=tf.int32, name=\"mask\")\n",
        "    doc_encoding = bert_layer(input_ids=ids, attention_mask=mask)[0][:,0,:]\n",
        "    dense = tf.keras.layers.Dense(32, activation='relu', name='encoding')(doc_encoding)\n",
        "    drop = tf.keras.layers.Dropout(0.1)(dense)\n",
        "    # Final output \n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(drop)\n",
        "    model = Model(inputs=[ids, mask], outputs=outputs)\n",
        "    model.compile(Adam(lr=1e-5), loss=BinaryFocalLoss(gamma=2), metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj3tHfoTuaun"
      },
      "source": [
        "def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tj5qItl-nHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7fc705-be9c-4f56-80ed-d00aeecb10ca"
      },
      "source": [
        "from transformers import TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
        "\n",
        "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "DISTILBERT_DROPOUT = 0.2\n",
        "DISTILBERT_ATT_DROPOUT = 0.2\n",
        "\n",
        "dis_config = DistilBertConfig()\n",
        "dis_config.dropout = DISTILBERT_DROPOUT\n",
        "dis_config.configattention_dropout=DISTILBERT_ATT_DROPOUT\n",
        "\n",
        "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "dbert_model.config = dis_config\n",
        "\n",
        "for layer in dbert_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHq2Xn9I_csA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a624ab5-10be-45a7-d7de-a4a2810b88f6"
      },
      "source": [
        "#Encoding text for hate datasets\n",
        "ha_train_input = bert_encode(hate_train_df.text, dbert_tokenizer, max_len=160)\n",
        "ha_val_input = bert_encode(hate_val_df.text, dbert_tokenizer, max_len=160)\n",
        "ha_test_input = bert_encode(hate_test_df.text, dbert_tokenizer, max_len=160)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ezzTVsDYKT",
        "outputId": "1bdfdd3a-b107-41c6-ee15-62f6f55601fa"
      },
      "source": [
        "model = build_model(dbert_model, max_len=160)\n",
        "model.summary()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ids (InputLayer)                [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask (InputLayer)               [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    ids[0][0]                        \n",
            "                                                                 mask[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 768)          0           tf_distil_bert_model[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoding (Dense)                (None, 32)           24608       tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 32)           0           encoding[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, 1)            33          dropout_20[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,387,521\n",
            "Trainable params: 24,641\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jbpftHJ3qHe"
      },
      "source": [
        "#Training Hate model\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0.001, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n",
        "]"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb0Q_51FE-PF",
        "outputId": "46a3ec19-6cc7-4ff6-d9eb-061fa737ebed"
      },
      "source": [
        "train_history = model.fit(\n",
        "    ha_train_input, hate_train_df.label,\n",
        "    validation_data=(ha_val_input, hate_val_df.label),\n",
        "    epochs=25,\n",
        "    callbacks=callbacks,\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "473/473 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.5050WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "473/473 [==============================] - 43s 79ms/step - loss: 0.1908 - accuracy: 0.5051 - val_loss: 0.1751 - val_accuracy: 0.5500\n",
            "Epoch 2/25\n",
            "473/473 [==============================] - 36s 75ms/step - loss: 0.1791 - accuracy: 0.5606 - val_loss: 0.1708 - val_accuracy: 0.5950\n",
            "Epoch 3/25\n",
            "473/473 [==============================] - 36s 75ms/step - loss: 0.1726 - accuracy: 0.5822 - val_loss: 0.1673 - val_accuracy: 0.6140\n",
            "Epoch 4/25\n",
            "473/473 [==============================] - 36s 75ms/step - loss: 0.1694 - accuracy: 0.5982 - val_loss: 0.1662 - val_accuracy: 0.6150\n",
            "Epoch 5/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1677 - accuracy: 0.5951 - val_loss: 0.1640 - val_accuracy: 0.6250\n",
            "Epoch 6/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1639 - accuracy: 0.6236 - val_loss: 0.1634 - val_accuracy: 0.6250\n",
            "Epoch 7/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1635 - accuracy: 0.6274 - val_loss: 0.1621 - val_accuracy: 0.6310\n",
            "Epoch 8/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1629 - accuracy: 0.6250 - val_loss: 0.1615 - val_accuracy: 0.6350\n",
            "Epoch 9/25\n",
            "473/473 [==============================] - 36s 75ms/step - loss: 0.1602 - accuracy: 0.6318 - val_loss: 0.1613 - val_accuracy: 0.6360\n",
            "Epoch 10/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1586 - accuracy: 0.6493 - val_loss: 0.1608 - val_accuracy: 0.6380\n",
            "Epoch 11/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1553 - accuracy: 0.6613 - val_loss: 0.1595 - val_accuracy: 0.6410\n",
            "Epoch 12/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1575 - accuracy: 0.6544 - val_loss: 0.1600 - val_accuracy: 0.6460\n",
            "Epoch 13/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1572 - accuracy: 0.6566 - val_loss: 0.1595 - val_accuracy: 0.6440\n",
            "Epoch 14/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1539 - accuracy: 0.6703 - val_loss: 0.1588 - val_accuracy: 0.6410\n",
            "Epoch 15/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1523 - accuracy: 0.6729 - val_loss: 0.1587 - val_accuracy: 0.6420\n",
            "Epoch 16/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1530 - accuracy: 0.6720 - val_loss: 0.1586 - val_accuracy: 0.6420\n",
            "Epoch 17/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1525 - accuracy: 0.6734 - val_loss: 0.1586 - val_accuracy: 0.6420\n",
            "Epoch 18/25\n",
            "473/473 [==============================] - 36s 75ms/step - loss: 0.1524 - accuracy: 0.6729 - val_loss: 0.1586 - val_accuracy: 0.6420\n",
            "Epoch 19/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1518 - accuracy: 0.6794 - val_loss: 0.1587 - val_accuracy: 0.6420\n",
            "Epoch 20/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1505 - accuracy: 0.6755 - val_loss: 0.1585 - val_accuracy: 0.6420\n",
            "Epoch 21/25\n",
            "473/473 [==============================] - 35s 75ms/step - loss: 0.1532 - accuracy: 0.6752 - val_loss: 0.1586 - val_accuracy: 0.6440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-6914NE01QH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87f8375-3d81-4b63-93f4-0dc31bdfb956"
      },
      "source": [
        "# model.evaluate(test_input, y_test,batch_size=200)\n",
        "test_pred = model.predict(ha_test_input)\n",
        "y_pred = [i[0] for i in test_pred.round().astype(int)]\n",
        "cm = confusion_matrix(hate_test_df.label,y_pred)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz-6hlJhzQYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "cb4ec0a3-f292-4788-ecc4-76ec0b98548c"
      },
      "source": [
        "plot_confusion_matrix(cm, normalize=False,target_names=['Not_hate', 'Hate'],title=\"Confusion Matrix for Hate\")"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJTnHxTSov91",
        "outputId": "de259957-9139-4498-8811-b78dd6a3699c"
      },
      "source": [
        "model.evaluate(ha_test_input, hate_test_df.label, verbose=True)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 10s 103ms/step - loss: 0.1780 - accuracy: 0.5505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1779773235321045, 0.5505050420761108]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq7hb-tuTItb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18815c76-685f-4312-ba46-96acf5d07592"
      },
      "source": [
        "#Encoding text for irony datasets\n",
        "ir_train_input = bert_encode(irony_train_df.text, dbert_tokenizer, max_len=160)\n",
        "ir_val_input = bert_encode(irony_val_df.text, dbert_tokenizer, max_len=160)\n",
        "ir_test_input = bert_encode(irony_test_df.text, dbert_tokenizer, max_len=160)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv6B9XjEWDRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a31064-e7e8-4b9b-8790-ac049a1508a4"
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "ir_model = build_model(dbert_model, max_len=160)\n",
        "\n",
        "train_history = ir_model.fit(\n",
        "    ir_train_input, irony_train_df.label,\n",
        "    validation_data=(ir_val_input, irony_val_df.label),\n",
        "    epochs=25,\n",
        "    callbacks=callbacks,\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "177/178 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.4957WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "178/178 [==============================] - 22s 95ms/step - loss: 0.2530 - accuracy: 0.4958 - val_loss: 0.1918 - val_accuracy: 0.4984\n",
            "Epoch 2/25\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.1999 - accuracy: 0.5092 - val_loss: 0.1832 - val_accuracy: 0.5047\n",
            "Epoch 3/25\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.1880 - accuracy: 0.5257 - val_loss: 0.1807 - val_accuracy: 0.5131\n",
            "Epoch 4/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1829 - accuracy: 0.5271 - val_loss: 0.1785 - val_accuracy: 0.5173\n",
            "Epoch 5/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1859 - accuracy: 0.5069 - val_loss: 0.1767 - val_accuracy: 0.5162\n",
            "Epoch 6/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1825 - accuracy: 0.5260 - val_loss: 0.1755 - val_accuracy: 0.5267\n",
            "Epoch 7/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1818 - accuracy: 0.5204 - val_loss: 0.1746 - val_accuracy: 0.5277\n",
            "Epoch 8/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1783 - accuracy: 0.5324 - val_loss: 0.1739 - val_accuracy: 0.5330\n",
            "Epoch 9/25\n",
            "178/178 [==============================] - 16s 87ms/step - loss: 0.1800 - accuracy: 0.5301 - val_loss: 0.1732 - val_accuracy: 0.5476\n",
            "Epoch 10/25\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.1760 - accuracy: 0.5353 - val_loss: 0.1725 - val_accuracy: 0.5518\n",
            "Epoch 11/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1773 - accuracy: 0.5502 - val_loss: 0.1720 - val_accuracy: 0.5665\n",
            "Epoch 12/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1755 - accuracy: 0.5506 - val_loss: 0.1712 - val_accuracy: 0.5623\n",
            "Epoch 13/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1749 - accuracy: 0.5461 - val_loss: 0.1705 - val_accuracy: 0.5654\n",
            "Epoch 14/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1739 - accuracy: 0.5603 - val_loss: 0.1705 - val_accuracy: 0.5644\n",
            "Epoch 15/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1764 - accuracy: 0.5344 - val_loss: 0.1704 - val_accuracy: 0.5654\n",
            "Epoch 16/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1705 - accuracy: 0.5847 - val_loss: 0.1704 - val_accuracy: 0.5644\n",
            "Epoch 17/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1726 - accuracy: 0.5419 - val_loss: 0.1704 - val_accuracy: 0.5654\n",
            "Epoch 18/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1721 - accuracy: 0.5447 - val_loss: 0.1703 - val_accuracy: 0.5675\n",
            "Epoch 19/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1738 - accuracy: 0.5590 - val_loss: 0.1703 - val_accuracy: 0.5686\n",
            "Epoch 20/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1729 - accuracy: 0.5650 - val_loss: 0.1703 - val_accuracy: 0.5675\n",
            "Epoch 21/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1740 - accuracy: 0.5614 - val_loss: 0.1703 - val_accuracy: 0.5686\n",
            "Epoch 22/25\n",
            "178/178 [==============================] - 15s 87ms/step - loss: 0.1753 - accuracy: 0.5304 - val_loss: 0.1702 - val_accuracy: 0.5686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlR06P4vXqUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7126bf-e35b-4509-ee73-e8a245b2b0bf"
      },
      "source": [
        "test_pred = ir_model.predict(ir_test_input)\n",
        "y_pred = [i[0] for i in test_pred.round().astype(int)]\n",
        "cm = confusion_matrix(irony_test_df.label,y_pred)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yENylN1Lyyi4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "0640c0e0-9716-4db8-a7b2-42b20baf5ce3"
      },
      "source": [
        "plot_confusion_matrix(cm, normalize=False,target_names=['Not_irony', 'irony'],title=\"Confusion Matrix for Irony\")"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHCCAYAAAAU60t9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1f3/8debIqCgoGABMdi7Ym/RYEvUFDUxlvi1JpZfTDexpKgxJjHGFo0lVmxBjV1jI5bEhooK2BC7giiiKFJEyuf3xz2Lw7pltszO3rnvJ4/72Jlz25nLPvYzn3POPVcRgZmZmeVTl2pXwMzMzFrPgdzMzCzHHMjNzMxyzIHczMwsxxzIzczMcsyB3MzMLMccyM0SSb0k3S7pY0n/asNx9pd0b3vWrRok3SXpoFbue4qkqZLebe96mdmiHMgtdyR9T9JoSTMkTU4B58vtcOi9gOWAZSLiu609SERcExFfbYf6LELSMEkh6eZ65Rum8gfLPM5Jkq5ubruI2DUirmhFPVcCjgbWiYjlW7p/I8cMSau1x7HMao0DueWKpF8AZwN/Igu6KwHnA7u3w+G/BEyIiHntcKxKeR/YStIyJWUHARPa6wTKtOVvw0rABxExpRXn7tYR+5jVEgdyyw1JSwEnA0dFxE0RMTMi5kbE7RHxq7RND0lnS3onLWdL6pHWDZM0UdLRkqakbP6QtO73wAnAPinT/379zFXSkJQZdkvvD5b0mqRPJL0uaf+S8odL9tta0pOpyf5JSVuXrHtQ0h8kPZKOc6+k/k1chs+AW4B90/5dgX2Aa+pdq79JelvSdElPSdo2le8C/Lrkc44tqccfJT0CzAJWSWU/SOsvkHRjyfH/Iuk+Sap33p2AkcDAdPzhqfxbkp6X9FE67tol+7wh6VhJ44CZzQXm9P9yg6SrJU0HDpY0UNJtkj6U9Iqkw+ptf72kK9M1fl7Spmndr0o/Vyo7R9LfmqqDWacSEV685GIBdgHmAd2a2OZkYBSwLDAAeBT4Q1o3LO1/MtAd2I0saPVL608Cri45Vv33Q4AAugFLANOBNdO6FYB10+uDgYfT66WBacABab/90vtl0voHgVeBNYBe6f2pjXy2YcBEYGvg8VS2G3AP8APgwZJt/w9YJp3zaOBdoGdDn6ukHm8B66Z9uqeyH6T1i5Nl/QcD2wJTgRWbqmfJ+zWAmcDO6bjHAK8Ai6X1bwBjgMFAr0aOGcBqJfWfC+xBloz0Av5H1jLTExhK1nKxQ8n2n6Zr1RX4MzCq5P9tJtA3ve8GTAE2qfbvuxcv5S7OyC1PlgGmRtNN3/sDJ0fElIh4H/g9WRCtMzetnxsRdwIzgDVbWZ8FwHqSekXE5Ih4voFtvg68HBFXRcS8iBgBjAe+WbLN5RExISJmA9eTBaJGRcSjwNKS1gQOBK5sYJurI+KDdM4zgB40/zmHR8TzaZ+59Y43i+w6nglcDfw4IiY2c7w6+wD/joiR6binkwXfrUu2OSci3k7XoByPRcQtEbEA6A9sAxwbEZ9GxBjgErJrU+fhiLgzIuYDVwEbps81mexLQN2YiF3IfseeKrMeZlXnQG558gHQv5mm14HAmyXv30xlC49R74vALKB3SysSETPJAtSRwGRJ/5a0Vhn1qavToJL3pSO7y63PVcCPgO2Bm+uvlPRLSS+m5vyPgKXIAl5T3m5qZUQ8DrwGiOwLR7kWuQYp+L7NotegyXM3oHT7gcCHEfFJSVlz17hnye/RFWQtGKSfV7WwLmZV5UBuefIYMIesSbUx75ANWquzUiprjZlkTcp1FhmBHRH3RMTOZM2z44GLy6hPXZ0mtbJOda4CfgjcmbLlhVJ/+DHA3mTdBn2Bj8kCMGTN1A1p8lGIko4iy+zfSccv1yLXIPWrD2bRa9DSxzCWbv8OWQtFn5KyllzjW4ANJK0HfIN64w3MOjsHcsuNiPiYbEDaeZL2kLS4pO6SdpV0WtpsBPBbSQPSoLETyJqCW2MMsJ2kldJAu+PrVkhaTtLukpYg+3Ixg6ypvb47gTWU3TLXTdI+wDrAHa2sEwAR8TrwFeA3DazuQzYW4H2gm6QTgCVL1r8HDGnJyHRJawCnkGWsBwDHSGqyC6DE9cDXJe0oqTtZn/0csvELbRYRb6dj/VlST0kbAN+nzP/3iPgUuAH4J/BERLzVHvUy6ygO5JYrqb/3F8BvyQLV22RNzLekTU4BRgPjgGeBp1NZa841ErguHespFg2+XVI93gE+JAuq/6+BY3xAluUdTdY1cAzwjYiY2po61Tv2wxHRUGvDPcDdZIPT3iQb6FXaFF032c0Hkp5u7jypCfpq4C8RMTYiXiYb+X5V3R0BzdTzJbIvAOeSDZL7JvDNiPisuX1bYD+ywYjvkHU1nBgR/2nB/lcA6+NmdcshRbS0RcvMrLYom8RmPLB8REyvdn3MWsIZuZkVWupi+AVwrYO45ZFnRDKzwkpjHN4j64LYpcrVMWsVN62bmZnlmJvWzczMcsyB3MzMLMfcR95Ci/XuGz2XXqHa1TAr24ypH1S7CmYtEp99Qsybrea3bJuuS34pYl65swI3Lma/f09EVG2MhQN5C/VcegW2PPbyalfDrGwPXdLa+XDMqmPOSy2ZAbj1Yt5seqy5d5uP8+mY85qb/riiHMjNzKygBOVPcNhpOZCbmVkxCVDFW/ArzoHczMyKqwYy8vx/AjMzswJzRm5mZsXlpnUzM7O88mA3MzOzfKuBjDz/X0XMzMwKzBm5mZkVk3DTupmZWX6pJprWHcjNzKy4aiAjz/8nMDMzKzBn5GZmVlxuWjczM8ur2riPPP+fwMzMrMCckZuZWTH56WdmZmY5VwNN6w7kZmZWUO4jNzMzsypzRm5mZsXVxX3kZmZm+eS51s3MzHKuBkat5/+riJmZWYE5Izczs4KqjVHrDuRmZlZcNdC07kBuZmbFVQMZef4/gZmZWYE5Izczs2KS3LRuZmaWazXQtO5AbmZmxVUDGXn+v4qYmZkVmDNyMzMrKN9HbmZmlm810LTuQG5mZsVUIw9Nyf8nMDMzKzBn5GZmVlC10Uee/09gZmbWWnWTwrRlafLwGizpAUkvSHpe0k9T+UmSJkkak5bdSvY5XtIrkl6S9LXmPoIzcjMzs8qZBxwdEU9L6gM8JWlkWndWRJxeurGkdYB9gXWBgcB/JK0REfMbO4EDuZmZFVeFm9YjYjIwOb3+RNKLwKAmdtkduDYi5gCvS3oF2Bx4rLEd3LRuZmbF1T5N6/0ljS5ZDm/4VBoCbAQ8nop+JGmcpMsk9Utlg4C3S3abSNOB3xm5mZkVlNptsNvUiNi06VOpN3Aj8LOImC7pAuAPQKSfZwCHtubkzsjNzMwqSFJ3siB+TUTcBBAR70XE/IhYAFxM1nwOMAkYXLL7iqmsUQ7kZmZWXJUftS7gUuDFiDizpHyFks32BJ5Lr28D9pXUQ9LKwOrAE02dw03rZmZWWKr8FK3bAAcAz0oak8p+DewnaShZ0/obwBEAEfG8pOuBF8hGvB/V1Ih1cCA3M7OCEpUP5BHxcDpVfXc2sc8fgT+Wew43rZuZmeWYM3IzMysm0XCunDMO5GZmVlDqiD7yinMgNzOzwqqFQO4+cjMzsxxzRm5mZoVVCxm5A7mZmRWWA7mZmVle1ciodfeRm5mZ5ZgzcjMzKyT59jMzM7N8cyA3MzPLsVoI5O4jNzMzyzFn5GZmVli1kJE7kJuZWTH59jMzMzOrNmfkZmZWWG5aNzMzyynfR25mZpZztRDI3UduZmaWY87IzcysuPKfkDuQm5lZQak2mtYdyM3MrLBqIZC7j9zMzCzHnJGbmVlh1UJG7kBuZmaF5PvIzczM8i7/cdx95GZmZnnmjNzMzIrJt5+ZmZnlmwO5mZlZjtVCIHcfuZmZWY45I7eKG9B7MX6146r0W7w7Adz5/BRuGfcufXp05TdfW53l+vTgvU/mcMo9LzNjznwG9+3J0TuuymoDlmD4qLe5Yczkan8EK5gVl+vLJX84kGWX6UMEXHbjI5w34kGuOvUQVh+yHAB9+/Tio09ms+W+p7LDFmvxh598i8W6d+OzufP49dm38N8nJ1T5U1hZ8p+QO5Bb5c1fEFz0yJu8MnUWvbp34by91+fptz/mq2sN4JmJ07nu6XfYZ+OB7LPxIC597C0+mTOP8x96g61XXrraVbeCmjd/AcedeRNjxk+k9+I9ePSfx3Lf4+M54LjLF25z6i/25OMZswH44KMZ7PWzfzD5/Y9ZZ9UVuP38o1j1a7+tVvWtBdy0blaGD2fN5ZWpswCYPXcBb02bTf8lFmOrlfsxcvz7AIwc/z5br9wPgI9mz2PClJnMXxBVq7MV27tTpzNm/EQAZsyaw/jX32XggL6LbPOdnTfm+rufAmDsSxOZ/P7HALzw6mR69ujOYt2dJ3V2ktplqTYHcutQy/XpwWr9l2D8ezPot3h3Ppw1F8iCfb/Fu1e5dmZftNIKSzN0zRV58rk3FpZts/GqvPfhJ7z61vtf2H7PnYYyZvzbfDZ3XgfW0orMXxmtw/Ts3oUTdlmdCx5+g1lz539hfTgBt05miV6LMeL0H/Cr02/kk5mfLizfe5dN+dfdo7+w/dqrLM8pP9mdb/zwvI6sprVBZ8io26piGbmkkHRGyftfSjqpmX32kLROM9ucLGmndqqmdZCuXcQJu6zB/ROm8shr0wCYNmsuS6csfOnFu/PR7LnVrKLZIrp168KI0w/jurtGc+v9YxeWd+3ahd132JAb7nl6ke0HLduX6848nB/87ipenzi1o6trreSm9abNAb4tqX8L9tkDaDKQR8QJEfGf+uWSurawftaBfrH9Krw1bTY3jn13YdmoN6ax81oDANh5rQE89vq0alXP7AsuPHF/Xnr9Xc65+v5FynfYYk0mvPEek6Z8tLBsqd69uOncI/ndObfy2NjXOrqq1hZqh6Wpw0uDJT0g6QVJz0v6aSr/q6TxksZJullS31Q+RNJsSWPScmFzH6GSgXwecBHw8/orUkXvTx/gPkkrSdoa+Bbw11T5VRs6qKThkvZKr9+Q9BdJTwPflbSfpGclPSfpLyX7zJD0R0ljJY2StJykPpJel9Q9bbNk6ft65zxc0mhJo+fO+Kj+amvGuiv0Yee1BjB00JJcsM/6XLDP+mz2pb5c+9Q7bDx4KS7ff0M2WnEprnt6EgD9Fu/ONQdtxLeHLs/3Nh3ENQdtxOLd/T3NOs7WQ1dh/29swVc2W4NR1x7HqGuP42tfznKM735tk4WD3Oocue92rDp4AMcfvuvC7Qf0612NqlvnMw84OiLWAbYEjkotzyOB9SJiA2ACcHzJPq9GxNC0HNncCRQV6piUNAMYCIwDNgQOA3pHxEmSbgduiIgrJB0KfCsi9pA0HLgjIm5o4rgLt5H0BnB+RJwmaSAwCtgEmAbcC5wTEbdIinSO2yWdBkyPiFMkXQ7cmrY5HFgzIo5u6nMtudLaseWxlze1iVmn8tAlV1e7CmYtMuel61kwa0rF26x7LLd6DNr/b20+zutnff2piNi0nG0l3Qr8PSJGlpTtCewVEftLGkIW49Yr9/wVHbUeEdOBK4Gf1Fu1FfDP9Poq4MttOM116edmwIMR8X5EzAOuAbZL6z4D7kivnwKGpNeXAIek14cAjtBmZkWhdusj71/XapuWwxs8XRakNwIer7fqUOCukvcrS3pG0n8lbdvcx+iIUetnA09TuSA5s4xt5sbnTQ/zSZ87Ih5JzfzDgK4R8VyF6mhmZrVranMZuaTewI3Az1KSW1f+G7Lm92tS0WRgpYj4QNImwC2S1i3dp76K30ceER8C1wPfLyl+FNg3vd4feCi9/gTo08pTPQF8RVL/NPBtP+C/Zex3JVnrgLNxM7MCESC1fWn2PNnYqxuBayLippLyg4FvAPvXJZsRMSciPkivnwJeBdZo6vgdNSHMGUDp6PUfA4dIGgccAPw0lV8L/Co1KTQ42K0xETEZOA54ABgLPBURt5ax6zVAP2BES85nZmZ5V/mZ3ZRtcCnwYkScWVK+C3AM2fitWSXlA+ruwpK0CrA60OStEBVrWo+I3iWv3wMWL3n/JrBDA/s8QvO3nx1c8npIvXUjaCAg16vLDUDpYLovkw2883B0M7OC6YDbwLchS1iflTQmlf0aOAfoAYxMXwZGpRHq2wEnS5oLLACOTC3bjSr0zG6SzgV2BXardl3MzKz2RMTDNHy3+Z2NbH8jWTN82TptIJd0Htk3mVJ/i4h268uOiB+317HMzCx/mmsaz4NOG8gj4qhq18HMzGpYmYPVOrtOG8jNzMwqSUCXLvmP5H6MqZmZWY45Izczs8Jy07qZmVmOebCbmZlZXtXIYDf3kZuZmeWYM3IzMyukbK71/KfkDuRmZlZQzc+VngcO5GZmVlg1EMfdR25mZpZnzsjNzKyw3LRuZmaWVzVy+5kDuZmZFVKtjFp3H7mZmVmOOSM3M7PCqoGE3IHczMyKy03rZmZmVlXOyM3MrLBqICF3IDczs4JSbTStO5CbmVkhZbefVbsWbec+cjMzsxxzRm5mZgXlp5+ZmZnlWg3EcQdyMzMrrlrIyN1HbmZmlmPOyM3MrJj89DMzM7P8qpWnnzmQm5lZYdVCIHcfuZmZWY45Izczs8KqgYTcgdzMzIqrFprWHcjNzKyYamTUuvvIzczMcswZuZmZFZI817qZmVm+1UAcdyA3M7Pi6lIDkdx95GZmZhUiabCkByS9IOl5ST9N5UtLGinp5fSzXyqXpHMkvSJpnKSNmzuHA7mZmRWW1PalGfOAoyNiHWBL4ChJ6wDHAfdFxOrAfek9wK7A6mk5HLiguRM4kJuZWSFlgVhtXpoSEZMj4un0+hPgRWAQsDtwRdrsCmCP9Hp34MrIjAL6SlqhqXM4kJuZmbVNf0mjS5bDG9pI0hBgI+BxYLmImJxWvQssl14PAt4u2W1iKmuUB7uZmVlhdWmfsW5TI2LTpjaQ1Bu4EfhZREwvzeQjIiRFa0/uQG5mZoXVEfeRS+pOFsSviYibUvF7klaIiMmp6XxKKp8EDC7ZfcVU1ig3rZuZWWFVerCbsm8KlwIvRsSZJatuAw5Krw8Cbi0pPzCNXt8S+LikCb5BzsjNzMwqZxvgAOBZSWNS2a+BU4HrJX0feBPYO627E9gNeAWYBRzS3AkcyM3MrJBENk1rJUXEw+lUDdmxge0DOKol53AgNzOzwmqnwW5V5UBuZmbFVMZ94HngwW5mZmY55ozczMwKqwYScgdyMzMrJlEbTz9zIDczs8KqgTjuPnIzM7M8c0ZuZmaFVQuj1h3IzcyskMp8nnin50BuZmaFVdOD3SSdCzT6WLWI+ElFamRmZmZlayojH91htTAzM6uC/OfjTQTyiLii9L2kxSNiVuWrZGZm1jFqYbBbs7efSdpK0gvA+PR+Q0nnV7xmZmZmFZRNCNP2pdrKuY/8bOBrwAcAETEW2K6SlTIzM7PylDVqPSLertf8ML8y1TEzM+sgNfL0s3IC+duStgZCUnfgp8CLla2WmZlZ5dVAHC+raf1I4ChgEPAOMDS9NzMzsyprNiOPiKnA/h1QFzMzsw5VC03r5YxaX0XS7ZLelzRF0q2SVumIypmZmVVKkUat/xO4HlgBGAj8CxhRyUqZmZl1BKUBb21Zqq2cQL54RFwVEfPScjXQs9IVMzMzs+Y1Ndf60unlXZKOA64lm3t9H+DODqibmZlZRVU/n267pga7PUUWuOs+5xEl6wI4vlKVMjMzqzSpxp9+FhErd2RFzMzMOloNxPHyZnaTtB6wDiV94xFxZaUqZWZmZuVpNpBLOhEYRhbI7wR2BR4GHMjNzCzXOsOo87YqZ9T6XsCOwLsRcQiwIbBURWtlZmbWAaS2L9VWTtP67IhYIGmepCWBKcDgCtfLzMysooRqe7BbidGS+gIXk41knwE8VtFamZmZWVnKmWv9h+nlhZLuBpaMiHGVrZaZmVmFdZKm8bZqakKYjZtaFxFPV6ZKndvqA5bgtiO2rHY1zMq2wZsfVbsKZi3y1uR7O+xctTDYramM/Iwm1gWwQzvXxczMrEOVM+K7s2tqQpjtO7IiZmZm1nJlTQhjZmZWa0TtN62bmZnVtM7wPPG2ciA3M7PCqoVA3mw/vzL/J+mE9H4lSZtXvmpmZmbWnHIG7J0PbAXsl95/ApxXsRqZmZl1gGyKVbV5af48ukzSFEnPlZRdJ2lMWt6QNCaVD5E0u2Tdhc0dv5ym9S0iYmNJzwBExDRJi5Wxn5mZWafWQU3rw4G/U/KwsYjYp+61pDOAj0u2fzUihpZ78HIC+VxJXcnuHUfSAGBBuScwMzMrsoj4n6QhDa1TltLvTRvmZimnaf0c4GZgWUl/JHuE6Z9ae0IzM7POop2eftZf0uiS5fAWVGFb4L2IeLmkbGVJz0j6r6RtmztAOXOtXyPpKbJHmQrYIyJebEElzczMOh1Bez39bGpEbNrKffcDRpS8nwysFBEfSNoEuEXSuhExvbEDNBvIJa0EzAJuLy2LiLdaWWkzM7NOoZpTtErqBnwb2KSuLCLmAHPS66ckvQqsAYxu7Djl9JH/m6x/XEBPYGXgJWDd1lbezMzM2AkYHxET6wrSOLQPI2K+pFWA1YHXmjpIOU3r65e+T09F+2Ejm5uZmeVGR8zQKmkEMIysL30icGJEXArsy6LN6gDbASdLmks2sPzIiPiwqeO3eGa3iHha0hYt3c/MzKwzkdRefeRNioj9Gik/uIGyG4EbW3L8cvrIf1HytguwMfBOS05iZmbWGdXAM1PKysj7lLyeR9Zn3qJvC2ZmZlYZTQbyNBFMn4j4ZQfVx8zMrMPUwkNTGg3kkrpFxDxJ23RkhczMzDpCO95HXlVNZeRPkPWHj5F0G/AvYGbdyoi4qcJ1MzMzq6gaiONl9ZH3BD4gmwe27n7yABzIzczMqqypQL5sGrH+HJ8H8DpR0VqZmZlVmmq8jxzoCvRm0QBex4HczMxyTw2GuHxpKpBPjoiTO6wmZmZmHSgb7FbtWrRdU/PF18DHMzMzq21NZeQ7dlgtzMzMqqAWMvJGA3lzk7SbmZnlnWrg/rMWPzTFzMysFhShj9zMzMw6OWfkZmZWTCrOzG5mZmY1qdbnWjczM6tZ7iM3MzOzqnNGbmZmhVUDLesO5GZmVlSiSw1MYuqmdTMzsxxzRm5mZoUk3LRuZmaWXwV4HrmZmVlNq4X7yN1HbmZmlmPOyM3MrJDcR25mZpZztdC07kBuZmaFVQNx3H3kZmZmeeaM3MzMCknURjbrQG5mZsUkUA20rTuQm5lZYeU/jNdGq4KZmVlhOSM3M7NCEr79zMzMLNfyH8YdyM3MrMBqICF3H7mZmVmeOSM3M7OCUk3cfuaM3MzMCqluQpi2Ls2eR7pM0hRJz5WUnSRpkqQxadmtZN3xkl6R9JKkrzV3fGfkZmZWWB2UkQ8H/g5cWa/8rIg4vV591gH2BdYFBgL/kbRGRMxv7ODOyM3MzCooIv4HfFjm5rsD10bEnIh4HXgF2LypHRzIzcyssNQOC9Bf0uiS5fAyT/8jSeNS03u/VDYIeLtkm4mprFFuWjczs2Jqv7nWp0bEpi3c5wLgD0Ckn2cAh7bm5M7IzczMOlhEvBcR8yNiAXAxnzefTwIGl2y6YiprlAO5mZkVUkeNWm/w3NIKJW/3BOpGtN8G7Cuph6SVgdWBJ5o6lpvWzcyssDpi1LqkEcAwsr70icCJwDBJQ8ma1t8AjgCIiOclXQ+8AMwDjmpqxDo4kJuZWYF1xM1nEbFfA8WXNrH9H4E/lnt8N62bmZnlmDNyMzMrrBqYodWB3MzMiikb7Jb/SO5AbmZmhVULGbn7yM3MzHLMGbmZmRWUkJvWzczM8qsWmtYdyM3MrJBqZbCb+8jNzMxyzBm5mZkVk9y0bmZmlmsO5GZmZjlWC6PW3UduZmaWY87IzcyskAR0yX9C7kBuZmbFVQtN6w7kZmZWWLUw2M195GZmZjnmjNw63Dlnn8Xwyy9BEuuutz4XXXI5jz36CL8+9lcsWLCAJXr35uJLh7PqaqtVu6pWUMsv1ZPT9l2f/r17EBFc9/hErnzkTY75+prssPYAPpsfvP3BLI67/lk++XQeGwxeij98Z10g63c9d+QrjHx+SnU/hJXFTetmLTRp0iTOP+8cnhn3Ar169WL//fbmX9ddy2l/+RP/uvFW1lp7bf5xwfmc+qdTuPiy4dWurhXU/AXBqXe8xAuTprNEj67c9JOteeTlqTwyYSpn3DWB+QuCX+66Bkdsvwqn3zWBCe9+wrfPeYz5C4IBfXpw28+35v4X32f+gqj2R7Em1MpgNzetW4ebN28es2fPzn7OmsUKAwciienTpwMwffrHrDBwYJVraUX2/idzeGFS9vs4c858Xp0yg+WW6skjL3+wMDiPfesjlu/bE4BP5y5YWN6jWxfC8ds6kDNy61CDBg3iZz//JWusshK9evVix52+yk47f5Xz/3EJe35rN3r26sWSSy7Jfx8eVe2qmgEwqF8v1hm4JGPf+miR8u9stiJ3jp288P0Gg5fiz99dj4H9enHMteOcjedCbTzGNJcZuaRHq10Ha51p06Zxx+238uLLr/PaW+8wc9ZMRlxzNef+7Sxuvu1OXn1jIgccdAjH/vIX1a6qGYsv1pVzDxjKn24fz8w58xeWH7nDKsxfENz2zOeBfNzbH/P1Mx9hr3Mf44jtV2Gxbrn881osaa71ti7VlsvftIjYun6ZJLcu5MD99/2HIUNWZsCAAXTv3p099vg2jz36CM+OG8vmW2wBwF7f3YdRo/xdzaqrWxdx7gEbcfszk7n3ufcWlu+5ySC2X3tZjh4xtsH9Xp0yk5mfzWeN5Xt3VFWtDdQOS7XlMpBLmpF+DpP0kKTbgBck9ZR0uaRnJT0jafu03cGSbpJ0t6SXJZ2Wyg+VdHbJcQ+TdFZVPlRBDB68Ek88MYpZs2YRETxw/32stfY6TP/4Y16eMAGA+/8zkjXXWrvKNbWi+9N31+PVKTO4/KE3FpZtu0Z/Dhu2MkcOf4pP5y5YWL5iv150TaOmBvbtySrLLsGkD2d3dJWtoGohi90YWC8iXpd0NGFGOYIAABePSURBVBARsb6ktYB7Ja2RthsKbATMAV6SdC5wPfAbSb+KiLnAIcAR9U8g6XDgcIDBK61U+U9UwzbfYgv2/PZebLX5xnTr1o0NN9yI7x92OINWXJH99v4OXbp0oW+/fvzj4suqXVUrsE2G9GWPTQYxfvIn3PqzrAHwzLsn8Ntvrc1i3bow/LDNABjz1keceNMLbLJyPw4ftjLzFgQLIvj9zS8wbdbcan4EK0M2ar0z5NRto8jh8EpJMyKit6RhwIkRUZd53wycGxH3p/cPAUeRBfttIuKwVH4X8MeIeFjSxcCdwIvAVRGxWVPn3mSTTeORx0dX6qOZtbsNfn13tatg1iJvXfkTPn13QsUj7NrrbxSX3/xAm4+z1er9noqITduhSq1SCxn5zDK3m1Pyej6ff/ZLgF8D44HL27FeZmbW2eU/Ic9nH3kTHgL2B0hN6isBLzW1Q0Q8DgwGvgeMqHQFzczM2lMtZOSlzgcukPQsMA84OCLmqPk+kOuBoRExrdIVNDOzzqMW7iPPZSCPiN7p54PAgyXln5INWKu//XBgeMn7b9Tb5MuAR6ubmRVMDYx1q7mm9RaR1FfSBGB2RNxX7fqYmVnHqoX7yHOZkbeXiPgIWKPZDc3MzDqpQgdyMzMruM6QUreRA7mZmRVS1jSe/0juQG5mZsXUSR560laFHuxmZmaWd87IzcyssGogIXcgNzOzAquBSO6mdTMzKyi1y79mzyJdJmmKpOdKyv4qabykcZJultQ3lQ+RNFvSmLRc2NzxHcjNzMwqaziwS72ykWSP4N4AmAAcX7Lu1YgYmpYjmzu4A7mZmRWW1PalORHxP+DDemX3RsS89HYUsGJrP4MDuZmZFVJ7TM+a4nh/SaNLlsNbWJVDgbtK3q8s6RlJ/5W0bXM7e7CbmZlZ20yNiE1bs6Ok35A9rfOaVDQZWCkiPpC0CXCLpHUjYnpjx3BGbmZmxVXFp6ZIOhj4BrB/RARARMyJiA/S66eAV2nmmSDOyM3MrLCqNUWrpF2AY4CvRMSskvIBwIcRMV/SKsDqwGtNHcuB3MzMCqsjpmiVNAIYRtaXPhE4kWyUeg9gpLJKjEoj1LcDTpY0F1gAHBkRHzZ44MSB3MzMrIIiYr8Gii9tZNsbgRtbcnwHcjMzK6wamNjNgdzMzAqqjYPVOgsHcjMzK6xaeB65bz8zMzPLMWfkZmZWSKJjRq1XmgO5mZkVVg3EcQdyMzMrsBqI5O4jNzMzyzFn5GZmVli1MGrdgdzMzArLg93MzMxyrAbiuPvIzczM8swZuZmZFVcNpOQO5GZmVkjZVOv5j+QO5GZmVkyqjcFu7iM3MzPLMWfkZmZWWDWQkDuQm5lZgdVAJHfTupmZWY45Izczs4KSR62bmZnlWS2MWncgNzOzQhI10UXuPnIzM7M8c0ZuZmbFVQMpuQO5mZkVlge7mZmZ5VgtDHZzH7mZmVmOOSM3M7PCqoGE3IHczMwKqkaefuZAbmZmBZb/SO4+cjMzsxxzRm5mZoUk3LRuZmaWazUQxx3IzcysuGohI3cfuZmZWY45Izczs8LyFK1mZmZ5lv847kBuZmbFVQNx3H3kZmZmlSTpMklTJD1XUra0pJGSXk4/+6VySTpH0iuSxknauLnjO5CbmVkhSe2zlGE4sEu9suOA+yJideC+9B5gV2D1tBwOXNDcwR3IzcyssNQO/5oTEf8DPqxXvDtwRXp9BbBHSfmVkRkF9JW0QlPHdyA3M7PiUjss0F/S6JLl8DLOvFxETE6v3wWWS68HAW+XbDcxlTXKg93MzMzaZmpEbNranSMiJEVr93dGbmZmhdU+CXmrvFfXZJ5+Tknlk4DBJdutmMoa5UBuZmaF1UGD3RpyG3BQen0QcGtJ+YFp9PqWwMclTfANctO6mZlZBUkaAQwj60ufCJwInApcL+n7wJvA3mnzO4HdgFeAWcAhzR3fgdzMzAqqvFHnbRUR+zWyascGtg3gqJYc34HczMwKqVaeR+4+cjMzsxxzIDczM8sxN62bmVlh1ULTugO5mZkVlp9HbmZmlldtuw+803AfuZmZWY45Izczs0Jq4xSrnYYDuZmZFVcNRHIHcjMzK6xaGOzmPnIzM7Mcc0ZuZmaFVQuj1h3IzcyssGogjjuQm5lZgdVAJHcfuZmZWY45Izczs8KqhVHrDuRmZlZItfI8ckVEteuQK5LeB96sdj1qUH9garUrYdYC/p2tnC9FxIBKn0TS3WT/j201NSJ2aYfjtIoDuXUKkkZHxKbVrodZufw7a52FB7uZmZnlmAO5mZlZjjmQW2dxUbUrYNZC/p21TsF95GZmZjnmjNzMzCzHHMjNzMxyzIHczMwsxxzIzczakaSKT2RiVsqB3HJJWnRixfrvzapB0kDgZEnL+nfSOooDueVSRISkrSWdXfe+2nUyA3oDKwHLpd9RB3OrOAdyy52SP46vAqtKWqOa9TGTtDxAREwARgJ/kbSkv2BaR3Agt9wp+eM4HZgEbABuXrfqkLQi8HtJN0saBNwJPAosk9b776xVlCeEsVyRtC5wOXAM8DywKnAB8M2ImFjNullxSFJqOu8REXMkLQMcD/QA+gLDgKsj4vhq1tOKwd8UrdMrzbQj4nngSmAn4FpgTbKAvkbatms16mjFkoL4rsDVkk4DZkfEL4E/k/1+Pg9sIGnDatbTisEZueWCpK8B2wOjgP9ExAxJWwBHAFsDH0bE1tWsoxWHpM2Bs4C/AocDrwPnAhMiYkFqbv8dcE9E3FS9mloROCO3TqsuE0/N6X8CFgO+CvxZ0uCIeBz4EbApMFHSTlWrrBWGpC8BxwL3RcQtwF5AV+CHwLqSuqRunpnAbpK6ePyGVZIDuXVaqflyO7I+8F9FxC/I+sc/Bo6RtGJEzIqIGalscBWra8XRA5gI7CRpy4iYBfyMrG/8h8ASKXDPB86JiAUevW6V5KZ169QkrQI8B1wbEYemso2B/YElgJ8DSwH/AI6PiBeqVVerTSUD29YjC+LvAp8Bh5LdMz48Ip6U1BNYLSKeq2J1rYAcyK1TKfmj+SWy38830i09TwHnR8TJabtNgenpvl0k9U6ZuVm7k7QLcB7wALADcBQwGdiFbMDlhamrx6zDdat2BcxKpSC+B/BLYL6kZ4F/AkOBUel2n99ExGjI7tFNTZcO4lYRknqT3e54SET8T9JeZC1BJ5B19RxG1h9uVhXOyK1TkbQscAdwEPApsA3ZPbm/Jxvs9gSwBfBaRCyoUjWtICTtCIwDTgZuJxuFPl/ST4GvRsTX3Rpk1ebBbtZpSFoHWAeYB7waEa8D9wEB7BoRrwKDI+IVB3GrFEnd0s/Ngb+R/U5OBTYDBqbNngSmpBYhB3GrKgdy6xQkDSVrphxPNrjtdynTmQw8C6ySprr8rIrVtBomaTVJfSJinqTBwNnADRHxX+BiYG3gJEkXkt1Jcau/UFpn4EBuVSGpr6T+6fW2wG+BiyLiXeAqoBdws6T9yG7tuSf1hc+rWqWt1i0HrJ9uHZsEjAYOkDQ0It4im7NgBNk86kdGxC2+P9w6A/eRW4eTtDjZvNQXRMQ7aRrLu4EbI+JHqWlzGbLbexYAz0TEvdWrsRWFpD7AWGCTiJgm6XfAJsAJETGuurUza5gDuVWFpKXJ7gPfney2ng2Am4A/R8Ql1aybFZuk3YFTgS3JnrB3LNktZ0dHxLPVrJtZQ3z7mVVFRHwoaTOyh5/Mj4gLJO1D9hCKxSLi/CpX0QoqIm6VNJesaX1T4C9Ad7K7Jsw6HWfkVlVpfvSDgcci4rz0IJTrgW38WFKrpjQJzOXAWhHxcbXrY9YYB3KriroZ3NLrnYH/A8ZExFmSloyI6dWtoRlI+jowMyIerHZdzBrjpnWrKEldI2J+/fI0g5siMzINcDtQ0pci4s0qVNXsCyLi37DoF0+zzsYZuVVMeojEUOAFssk0ukXEPfW2Kc3M+0fE1I6vqZlZfvk+cqukxYDtgcuAS8hGAC+iLjNPmftUSV07upJmZnnmQG4Vk/q5/wtsBTwEvNLIpl3S/NV9gWPTvbxmZlYGB3Jrd3WzXUnqQTa5xg7A+8DP0+QvSFoq/eyagvhSZA+leCgiPqlOzc3M8sd95NauSp4nvgtwBPAu2ZSW1wNnAVOAacDewN4RMSll4jeRzZ71cJWqbmaWSx61bu2iZAR6SNoKOB34HTADuAhYnuwZ4z8mewzpGSmI9yLrQz/JQdzMrOWckVubSRoA7AGMiIgZkr4BbBsRx5asvx84kOzZzt0j4tO0rjuwYnpkqZmZtZAzcmsP25Bl2T0kXQ58SjZaHYCIeF/SfUCvdE/5fFjYPz4XcBA3M2slD3azViu5Vex24C5gTeDAiPgP8LSkJyWtm6Zh3QlY5BGkDU0UY2ZmLeOmdWsVSWsCPwDuBf4XEXMk7QrsCjwXERdJ+iMwCBgMnFk3S5aZmbUfB3JrFUlfAR4AXiYbkb4K8FdgZ7KJYCZFxPC0bZ+I+MTTXJqZtT8Hcms1SV8G7iDrH/8O0A/YE5gIrAacRDYinYhYUJ1ampnVNg92s1aLiIcl7QfcAGydsu47gPWBw4HXHcDNzCrLGbm1maTdgHOBzSLiw1RWNzGMm9PNzCrIGbm1WUTcKWkBMF7SmhExrS54O4ibmVWWM3JrN5K+DsyMiAerXRczs6JwILd25+Z0M7OO40BuZmaWY57ZzczMLMccyM3MzHLMgdzMzCzHHMjN2pGk+ZLGSHpO0r8kLd6GYw2XtFd6fYmkdZrYdpikrVtxjjck9S+3vN42M1p4rpMk/bKldTSzpjmQm7Wv2RExNCLWAz4DjixdKalVczdExA8i4oUmNhkGtDiQm1n+OZCbVc5DwGopW35I0m3AC5K6SvpreszrOElHQHbbnqS/S3pJ0n+AZesOJOlBSZum17tIelrSWEn3SRpC9oXh56k1YFtJAyTdmM7xpKRt0r7LSLpX0vOSLgHU3IeQdIukp9I+h9dbd1Yqv0/SgFS2qqS70z4PSVqrPS6mmTXMM7uZVUDKvHcF7k5FGwPrRcTrKRh+HBGbSeoBPCLpXmAjsme6rwMsB7xAeuhMyXEHABcD26VjLR0RH0q6EJgREaen7f4JnJXmw18JuAdYGzgReDgiTk4T+Hy/jI9zaDpHL+BJSTdGxAfAEsDoiPi5pBPSsX8EXAQcGREvS9oCOB/YoRWX0czK4EBu1r56SRqTXj8EXErW5P1ERLyeyr8KbFDX/w0sBawObAeMiIj5wDuS7m/g+FuSPf/9dYC6ue0bsBOwjrQw4V5SUu90jm+nff8taVoZn+knkvZMrwenun4ALACuS+VXAzelc2wN/Kvk3D3KOIeZtZIDuVn7mh0RQ0sLUkCbWVoE/Dgi7qm33W7tWI8uwJYR8WkDdSmbpGFkXwq2iohZkh4EejayeaTzflT/GphZ5biP3Kzj3QP8P0ndASStIWkJ4H/APqkPfQVg+wb2HQVsJ2nltO/SqfwToE/JdvcCP657I6kusP4P+F4q25XsGfJNWQqYloL4WmQtAnW6AHWtCt8ja7KfDrwu6bvpHJK0YTPnMLM2cCA363iXkPV/Py3pOeAfZK1jNwMvp3VXAo/V3zEi3id71vtNksbyedP27cCedYPdgJ8Am6bBdC/w+ej535N9EXierIn9rWbqejfQTdKLwKlkXyTqzAQ2T59hB+DkVL4/8P1Uv+eB3cu4JmbWSp5r3czMLMeckZuZmeWYA7mZmVmOOZCbtSNJPSRdJ+kVSY+nyVoa2u4NSc+mPu3RDaw/WlLUTZOaBo2dk447TtLGJdueliZleTFt07Kh6Y1/ljsl9W3hPsMk3dEe5y/zfI1el0a2vy316de9P0nSpPT/MKbuzgFJi0m6PP0fjU2j95G0uKR/SxqfrvmpFf2AZmXw7WdW8yR1i4h5HXS675ON8l5N0r7AX4B9Gtl2+4iYWr9Q0mCye81LB6LtSnb/9urAFsAFwBbK5lffBtggbfcw8BXgwbZ+kIhoz9vhKqXB69LQhpK+DTQ0P/xZdRPplDgMICLWl7QscJekzdK60yPiAUmLAfdJ2jUi7mqHz2LWKs7IrWrUyNSfqjcFaSrrXZIhjZP0nVQ+o2S/vSQNT6+HS7pQ0uPAaZI2l/SYpGckPSppzbRdV0mnK3vIyThJP5a0g6RbSo67s6Sby/xYuwNXpNc3ADu2IkM+CziG7L7s0uNeGZlRQN90i1qQ3de9GNnEK92B91K9L1Ga1rVUujYXSBol6bWURV+WMvrhJdu9Iam/pCVSFjo2Xad90vrN0rUcK+kJSX3qnaexa75u2n5MuuarN3aOMjR2Xep/5t7AL4BTyjzuOsD9ABExBfgI2DQiZkXEA6n8M+BpYMUyj2lWEc7IrZq+MPUn2ZfLRaYgTdv+jmxa0/UBJDV3/zNkf2C3joj5kpYEto2IeZJ2Av4EfIfsVq4hwNC0bmlgGnC+pAHpdq9DSFOlSrqObBrV+s6MiCuBQcDbAOl4HwPLAPUz7wDulRTAPyLionT83YFJETG2XvxfeNxkIjAoIh6T9AAwmWyimb9HxIvp/D9o4tr0A7YCvgXcRpbV/4Ds/2FoRIwp2XYX4J2I+Hqq41IpG70O2CcinkzXd3a9c4yn4Wt+JPC3iLgmHacrsFv9c6SfZ9Hw/fTXRsSpjV2XdD1K/QE4A5jVwLF+JOlAYDRwdERMA8YC35I0gmw2u03SzyfqdlLW7fBN4G8NHNOswziQWzU1NPXnABqegnQnYN+6HdMf2+b8K013CtnEJldIWp0siHYvOe6FdU3vdeeTdBXwf5IuJwt4B6b15WaKzflyRExKzbYjJY0nCyS/JmtWL4uk1cjmUK/LCkdK2jYiHmpm19sjIiQ9C7wXEc+m4z1P9sWmNJA/C5wh6S/AHRHxkKT1gckR8SRAmgim/sxxjV3zx4DfSFoRuCnNyf6Fc6Tj/rzca9EYZZPhrJrmhB9Sb/UFZEE++DzYH0r2xW1tsv+TN4FHgbrfpbq59EcA50TEa22to1lbuGndqkKLTv25IfAMjU/92ZTS5uf6+5dOi/oH4IH0eNFvlnGuy4H/A/Yj+0IwL9X7On0+MKp0OTDtN4nsS0ndH/ulyOYlX7TSEZPSzylkE8FsDqwKrAyMlfQGWXB+WtLypcdNVkxlewKjImJGRMwA7iL74tGcOenngpLXde8X+YIfERPIHvryLHCKsgeklKPBax4R/yRrCZgN3Clph8bOoezpag1d7+PSORq7LqW2Ipsc5w2yMQRrKJtqloh4LyLmR8QCspagzVP5vIj4eXok7e5AX2BCyTEvAl6OiLPLvBZmFeNAbtXS2NSfjU1BOhI4qm7nkqb19yStLakLWVBr6nx1f+APLikfCRyRgu7C80XEO8A7wG/JgjqpfJ/0x73+cmXa5DbgoPR6L+D+qDfrUuoP7lP3miwDfy4ino2IZSNiSEQMIWsm3jgi3k3HPVCZLcm6GSaTDYj7iqRuyqZ8/QrwYjr2lZI2b+KalEXSQGBWRFwN/JUs4L4ErKA0AExSH33xWesNXnNJqwCvRcQ5wK1kD5Bp6ByUBNP6S91o8cauy0IRcUFEDEzX9MvAhIgYlupS2p++J/BcKl88/d8gaWdgXqTnwUs6JX22n7XwUppVhAO5VUuDU382MQXpKUC/NBBqLJ/3mx4H3EHW9Fm/X7TUacCfJT3DohnnJWTBcFw67vdK1l0DvF3X51ymS4FlJL1CNrjqOMiCoaQ70zbLAQ+n8z0B/Dsi7m7waJ+7E3gNeIUsc/xhKr8BeJUskx0LjI2I29O6Dci+jLTV+sATyp7qdiJwShrotQ9wbvocI/liK0dj13xv4Ll0vPXIpqP9wjnKrFtj1wV9/hS6ppymNICS7Heqril/WbLWkBeBY4ED0jFXBH5DNhju6dQ60NRYBLOK8xStZo2Q9HfgmYi4tNp1aak0+OzSiPhutetiZpXlQG7WAElPkfWx7xwRc5rb3sysWhzIzczMcsx95GZmZjnmQG5mZpZjDuRmZmY55kBuZmaWYw7kZmZmOeZAbmZmlmP/H13rL6798WmGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Lk26rqzDCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468cc995-7333-4b3c-e902-8c742ee0f413"
      },
      "source": [
        "ir_model.evaluate(ir_test_input,irony_test_df['label'], verbose=True)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 3s 102ms/step - loss: 0.1725 - accuracy: 0.5408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17251987755298615, 0.5408163070678711]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eESkoNU_cWm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4aaf96-9b3d-435b-c3c6-8074a2e1dfc2"
      },
      "source": [
        "#Encoding text for offensive datasets\n",
        "of_train_input = bert_encode(offensive_train_df.text, dbert_tokenizer, max_len=160)\n",
        "of_val_input = bert_encode(offensive_val_df.text, dbert_tokenizer, max_len=160)\n",
        "of_test_input = bert_encode(offensive_test_df.text, dbert_tokenizer, max_len=160)\n",
        "of_test_input"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  101,  2003, 16374, ...,     0,     0,     0],\n",
              "        [  101,  1045,  2288, ...,     0,     0,     0],\n",
              "        [  101,  2065,  2017, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  2123,  2102, ...,     0,     0,     0],\n",
              "        [  101,  8398,  2003, ...,     0,     0,     0],\n",
              "        [  101,  2017,  2342, ...,     0,     0,     0]]),\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceAFM6O_cZQM",
        "outputId": "7d0d17bb-13b1-4681-c3a7-e62b49d0e651"
      },
      "source": [
        "K.clear_session()\n",
        "model_of = build_model(dbert_model, max_len=160)\n",
        "\n",
        "train_history = model_of.fit(\n",
        "    of_train_input, offensive_train_df.label,\n",
        "    validation_data=(of_val_input, offensive_val_df.label),\n",
        "    epochs=25,\n",
        "    callbacks=callbacks,\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "492/493 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.5069WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "493/493 [==============================] - 44s 80ms/step - loss: 0.1991 - accuracy: 0.5069 - val_loss: 0.1765 - val_accuracy: 0.5423\n",
            "Epoch 2/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1813 - accuracy: 0.5523 - val_loss: 0.1687 - val_accuracy: 0.6042\n",
            "Epoch 3/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1737 - accuracy: 0.5784 - val_loss: 0.1642 - val_accuracy: 0.6254\n",
            "Epoch 4/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1705 - accuracy: 0.5963 - val_loss: 0.1587 - val_accuracy: 0.6616\n",
            "Epoch 5/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1627 - accuracy: 0.6251 - val_loss: 0.1597 - val_accuracy: 0.6473\n",
            "Epoch 6/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1629 - accuracy: 0.6297 - val_loss: 0.1577 - val_accuracy: 0.6601\n",
            "Epoch 7/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1607 - accuracy: 0.6317 - val_loss: 0.1554 - val_accuracy: 0.6722\n",
            "Epoch 8/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1604 - accuracy: 0.6360 - val_loss: 0.1543 - val_accuracy: 0.6790\n",
            "Epoch 9/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1591 - accuracy: 0.6498 - val_loss: 0.1540 - val_accuracy: 0.6820\n",
            "Epoch 10/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1586 - accuracy: 0.6503 - val_loss: 0.1531 - val_accuracy: 0.6820\n",
            "Epoch 11/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1597 - accuracy: 0.6374 - val_loss: 0.1528 - val_accuracy: 0.6843\n",
            "Epoch 12/25\n",
            "493/493 [==============================] - 38s 77ms/step - loss: 0.1587 - accuracy: 0.6480 - val_loss: 0.1526 - val_accuracy: 0.6858\n",
            "Epoch 13/25\n",
            "493/493 [==============================] - 38s 76ms/step - loss: 0.1576 - accuracy: 0.6605 - val_loss: 0.1524 - val_accuracy: 0.6873\n",
            "Epoch 14/25\n",
            "492/493 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.6518"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aeMQAtocgix"
      },
      "source": [
        "test_pred = model_of.predict(of_test_input)\n",
        "y_pred = [i[0] for i in test_pred.round().astype(int)]\n",
        "cm = confusion_matrix(offensive_test_df.label,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb2A3hxaulB5"
      },
      "source": [
        "plot_confusion_matrix(cm, normalize=False,target_names=['Not_offensive', 'Offensive'],title=\"Confusion Matrix for offensive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k3p5Sswi-4W"
      },
      "source": [
        "model_of.evaluate(of_test_input,offensive_test_df['label'], verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_fjr48jOFl8"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(offensive_test_df.label,y_pred,average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}